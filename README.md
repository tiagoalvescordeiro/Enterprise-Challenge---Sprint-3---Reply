Hermes Reply â€“ SprintÂ 3 (FaseÂ 5)

Este repositÃ³rio contÃ©m a soluÃ§Ã£o completa para o desafio Hermes Reply (FaseÂ 5) da FIAP. O objetivo Ã© construir um pequeno sistema que integre Banco de Dados, Machine Learning e uma documentaÃ§Ã£o estruturada para monitorar sensores em um ambiente industrial. Todo o conteÃºdo estÃ¡ em portuguÃªs para facilitar a compreensÃ£o.

ğŸ—‚ Estrutura do RepositÃ³rio
â”œâ”€â”€ db          # Modelagem e scripts SQL
â”‚Â Â  â”œâ”€â”€ der.txt
â”‚Â Â  â””â”€â”€ script.sql
â”œâ”€â”€ ml          # CÃ³digo de Machine Learning e mÃ©tricas
â”‚Â Â  â”œâ”€â”€ main.py
â”‚Â Â  â””â”€â”€ metrics.txt
â”œâ”€â”€ data        # Conjunto de dados (CSV) utilizado no modelo
â”‚Â Â  â””â”€â”€ dataset.csv
â”œâ”€â”€ docs        # Imagens geradas (grÃ¡ficos, matriz de confusÃ£o)
â”‚Â Â  â”œâ”€â”€ matriz_confusao.png
â”‚Â Â  â”œâ”€â”€ scatter.png
â”‚Â Â  â””â”€â”€ bar_chart.png
â””â”€â”€ README.md   # Este documento

IntroduÃ§Ã£o

Sensores industriais coletam continuamente dados como temperatura e vibraÃ§Ã£o. Interpretar esses dados de forma automÃ¡tica pode ajudar a identificar anomalias e acionar alarmes. Neste projeto, definimos uma tarefa de classificaÃ§Ã£o que categoriza o estado do sensor em trÃªs nÃ­veis:

Normal â€“ operaÃ§Ã£o dentro dos limites esperados.

Alerta â€“ valores moderadamente elevados.

CrÃ­tico â€“ condiÃ§Ãµes que exigem intervenÃ§Ã£o imediata.

AlÃ©m do modelo de ML, foi projetado um banco relacional para persistir esses dados de forma estruturada.

ğŸ—„ Banco de Dados
DER textual

O documento db/der.txt
 descreve as entidades, atributos e relacionamentos de forma detalhada. As principais tabelas sÃ£o:

Sensor â€“ armazena metadados dos sensores (sensor_id, nome, localizacao).

Estado â€“ normaliza os estados possÃ­veis (estado_id, descricao).

Leitura â€“ registra cada observaÃ§Ã£o com data/hora, temperatura, vibraÃ§Ã£o, alÃ©m de chaves estrangeiras para Sensor e Estado.

O relacionamento Sensor 1:N Leitura indica que um sensor pode ter vÃ¡rias leituras ao longo do tempo. Da mesma forma, Estado 1:N Leitura conecta cada leitura ao estado classificado.

Script SQL

O script db/script.sql
 cria as tabelas, chaves primÃ¡rias e estrangeiras, insere os estados padrÃ£o e define Ã­ndices para otimizar consultas. Para executar o script:

Crie um banco de dados PostgreSQL (ou outro SGDB compatÃ­vel).

Execute o conteÃºdo de script.sql no console do banco ou via ferramenta grÃ¡fica.

Use a tabela Sensor para cadastrar seus dispositivos antes de inserir leituras.

ğŸ¤– Machine Learning
CriaÃ§Ã£o do Dataset

Um dataset artificial foi gerado contendo 1â€¯500 leituras (3 sensores Ã— 500 amostras), com colunas de temperatura, vibracao e o estado calculado (Normal, Alerta ou CrÃ­tico). O arquivo CSV estÃ¡ em data/dataset.csv
. Os valores foram simulados com distribuiÃ§Ã£o normal e regras de negÃ³cio simples:

Leituras com temperatura muito alta (>80â€¯Â°C) ou vibraÃ§Ã£o muito alta (>6) sÃ£o rotuladas como CrÃ­tico.

Leituras com temperatura moderada (>60â€¯Â°C) ou vibraÃ§Ã£o moderada (>4) sÃ£o Alerta.

Demais leituras sÃ£o Normais.

ImplementaÃ§Ã£o do Modelo

O cÃ³digo ml/main.py
 lÃª o CSV, codifica as classes, separa os dados em treino/teste (70/30), treina um modelo de RegressÃ£o LogÃ­stica e gera mÃ©tricas e grÃ¡ficos. A escolha da RegressÃ£o LogÃ­stica deveâ€‘se Ã  sua simplicidade e capacidade de lidar bem com problemas lineares multiclasse.

O script produz:

RelatÃ³rio de mÃ©tricas de classificaÃ§Ã£o (precisÃ£o, recall, f1â€‘score) salvo em ml/metrics.txt
.

Matriz de ConfusÃ£o (docs/matriz_confusao.png) para visualizar erros e acertos do modelo.

GrÃ¡fico de DispersÃ£o (docs/scatter.png) mostrando a distribuiÃ§Ã£o das leituras por estado.

GrÃ¡fico de Barras (docs/bar_chart.png) indicando o nÃºmero de registros de cada classe.

Principais Resultados

O modelo alcanÃ§ou boa performance, com mÃ©tricas de precisÃ£o e recall superiores a 90â€¯% para as classes Normal e CrÃ­tico, e cerca de 85â€¯% para a classe Alerta. Veja o relatÃ³rio completo em ml/metrics.txt
.

ğŸš€ InstruÃ§Ãµes de ExecuÃ§Ã£o

Preparar Ambiente â€“ Instale as dependÃªncias executando:

pip install -r requirements.txt


Executar SQL â€“ Crie as tabelas do banco conforme db/script.sql.

Gerar Dataset (Opcional) â€“ O CSV jÃ¡ estÃ¡ pronto, mas vocÃª pode regenerÃ¡â€‘lo com seu prÃ³prio script ou modificar a geraÃ§Ã£o conforme necessÃ¡rio.

Treinar o Modelo â€“ Execute o script de ML:

cd ml
python main.py


Visualizar Resultados â€“ ApÃ³s a execuÃ§Ã£o, consulte os arquivos em ml/metrics.txt e docs/*.png para entender a performance e os grÃ¡ficos.

ğŸ¬ Roteiro para VÃ­deo (â‰¤Â 5Â min)

IntroduÃ§Ã£o (30Â s) â€“ Apresentar o contexto do desafio Hermes Reply, a importÃ¢ncia de monitorar sensores industriais e os objetivos do projeto.

Banco de Dados (60Â s) â€“ Explicar a modelagem relacional. Descrever as entidades Sensor, Estado e Leitura, destacando as cardinalidades e justificando a normalizaÃ§Ã£o.

Machine Learning (90Â s) â€“ Mostrar como o dataset foi gerado, quais caracterÃ­sticas foram consideradas e por que a RegressÃ£o LogÃ­stica foi escolhida. Apontar como o cÃ³digo estÃ¡ organizado e comentado.

Resultados (60Â s) â€“ Exibir rapidamente a matriz de confusÃ£o e os grÃ¡ficos gerados, destacando as mÃ©tricas principais.

ConclusÃ£o (30Â s) â€“ Resumir aprendizados, possÃ­veis melhorias (ex.: usar dados reais, testar outros algoritmos) e convidar os espectadores a explorar o repositÃ³rio.

ğŸ“¹ Link do VÃ­deo

Adicionar aqui o link para o vÃ­deo explicativo assim que for gravado e hospedado.
